import React, { useEffect, useRef } from "react";
import { YouTubeMetadata } from "../services/geminiService";
import { sonicEngine } from "../services/proceduralAudio";

interface RecordingSystemProps {
  isRecording: boolean;
  getCanvas: () => HTMLCanvasElement | null;
  audioRef: React.RefObject<HTMLAudioElement | null>;
  metadata: YouTubeMetadata | null;
  durationMinutes: number;
  onRecordingComplete: (blob: Blob) => void;
}

const RecordingSystem: React.FC<RecordingSystemProps> = ({
  isRecording,
  getCanvas,
  audioRef,
  metadata,
  durationMinutes,
  onRecordingComplete,
}) => {
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const sourceNodeRef = useRef<MediaElementAudioSourceNode | null>(null);
  const streamDestRef = useRef<MediaStreamAudioDestinationNode | null>(null);
  const musicGainRef = useRef<GainNode | null>(null);
  const currentMimeType = useRef<string>("");

  const initAudioGraph = () => {
    const audioEl = audioRef.current;
    if (!audioEl) return null;

    const ctx = sonicEngine.getContext();
    if (!ctx) return null;

    try {
      // CRITICAL FIX: Check if audio element has a valid source before creating source node
      if (!audioEl.src && !audioEl.currentSrc) {
        console.warn(`‚ö†Ô∏è [AudioGraph] No audio source available, skipping audio graph setup`);
        // Return empty audio stream instead of null to avoid breaking the recorder
        const emptyDest = ctx.createMediaStreamDestination();
        return emptyDest.stream;
      }

      // ÿß€åÿ¨ÿßÿØ ÿ≥Ÿàÿ±ÿ≥ ÿµŸàÿ™€å (ŸÅŸÇÿ∑ €å⁄©ÿ®ÿßÿ± ÿ®ÿ±ÿß€å Ÿáÿ± ÿßŸÑŸÖŸÜÿ™ ÿØÿ± ÿ∑ŸàŸÑ ⁄Üÿ±ÿÆŸá ÿ≠€åÿßÿ™)
      if (!sourceNodeRef.current) {
        console.log(`üîä [AudioGraph] Creating MediaElementAudioSourceNode...`);
        try {
          sourceNodeRef.current = ctx.createMediaElementSource(audioEl);
          console.log(`‚úÖ [AudioGraph] Source node created successfully`);
        } catch (e) {
          console.error(`‚ùå [AudioGraph] Failed to create source node:`, e);
          // If we can't create source node, return empty stream
          const emptyDest = ctx.createMediaStreamDestination();
          return emptyDest.stream;
        }
      }

      // ÿß€åÿ¨ÿßÿØ ŸÖŸÇÿµÿØ ÿßÿ≥ÿ™ÿ±€åŸÖ ÿ®ÿ±ÿß€å ÿ∂ÿ®ÿ∑
      if (!streamDestRef.current) {
        streamDestRef.current = ctx.createMediaStreamDestination();
      }

      // ÿß€åÿ¨ÿßÿØ ⁄©ŸÜÿ™ÿ±ŸÑÿ± ŸàŸÑŸàŸÖ (Gain)
      if (!musicGainRef.current) {
        musicGainRef.current = ctx.createGain();
      }

      const musicSource = sourceNodeRef.current;
      const musicGain = musicGainRef.current;
      const dest = streamDestRef.current;

      // ŸÇÿ∑ÿπ ÿßÿ™ÿµÿßŸÑÿßÿ™ ŸÇÿ®ŸÑ€å ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿß€åŸÖŸÜ (ÿ¨ŸÑŸà⁄Ø€åÿ±€å ÿßÿ≤ ÿÆÿ∑ÿß€å Not Connected)
      try {
        musicSource.disconnect();
      } catch (e) {
        // ÿß⁄Øÿ± ŸÖÿ™ÿµŸÑ ŸÜÿ®ÿßÿ¥ÿØÿå ŸÜÿßÿØ€åÿØŸá ŸÖ€å‚Äå⁄Ø€åÿ±€åŸÖ
      }

      // ÿ®ÿ±ŸÇÿ±ÿßÿ±€å ÿßÿ™ÿµÿßŸÑÿßÿ™ ⁄Øÿ±ÿßŸÅ ÿµŸàÿ™€å
      musicSource.connect(musicGain);
      musicGain.connect(ctx.destination); // ÿ®ÿ±ÿß€å ÿ¥ŸÜ€åÿØŸÜ ÿµÿØÿß ÿßÿ≤ ÿßÿ≥Ÿæ€å⁄©ÿ±
      musicGain.connect(dest); // ÿ®ÿ±ÿß€å ÿßÿ±ÿ≥ÿßŸÑ ÿ®Ÿá ÿ±€å⁄©Ÿàÿ±ÿØÿ±

      console.log(`üéµ [AudioGraph] Audio routing complete: audio ‚Üí gain ‚Üí [speakers + recorder]`);

      // ÿßÿ™ÿµÿßŸÑ ÿßŸÅ⁄©ÿ™‚ÄåŸáÿß€å ÿµŸàÿ™€å ÿ≥€åÿ≥ÿ™ŸÖ (SFX) ÿ®Ÿá ÿ∂ÿ®ÿ∑
      const sfxGain = sonicEngine.getMasterGain();
      if (sfxGain) {
        try {
          sfxGain.disconnect(dest);
        } catch (e) {}
        sfxGain.connect(dest);
        console.log(`üîä [AudioGraph] SFX routing complete: sfx ‚Üí recorder`);
      }

      return dest.stream;
    } catch (e) {
      console.error("Critical Audio Graph Error:", e);
      // ÿØÿ± ÿµŸàÿ±ÿ™ ÿ®ÿ±Ÿàÿ≤ ÿÆÿ∑ÿßÿå ÿ≠ÿØÿßŸÇŸÑ ÿßÿ≥ÿ™ÿ±€åŸÖ ŸÖŸÇÿµÿØ ÿ±ÿß ÿ®ÿ±ŸÖ€å‚Äå⁄Øÿ±ÿØÿßŸÜ€åŸÖ ÿ™ÿß ÿ±€å⁄©Ÿàÿ±ÿØ ⁄©ŸÑÿß ŸÖÿ™ŸàŸÇŸÅ ŸÜÿ¥ŸàÿØ
      return streamDestRef.current?.stream || null;
    }
  };

  // Reset audio source node when audio source changes (important for Auto Mode with different tracks)
  useEffect(() => {
    const audioEl = audioRef.current;
    if (!audioEl) return;

    const handleLoadStart = () => {
      console.log(`üîÑ [RecordingSystem] Audio source changing, resetting source node...`);
      // Disconnect old source node safely
      if (sourceNodeRef.current) {
        try {
          sourceNodeRef.current.disconnect();
        } catch (e) {
          // Ignore disconnect errors
        }
        sourceNodeRef.current = null;
        console.log(`‚úÖ [RecordingSystem] Source node reset complete`);
      }
    };

    audioEl.addEventListener('loadstart', handleLoadStart);
    return () => {
      audioEl.removeEventListener('loadstart', handleLoadStart);
    };
  }, [audioRef]);

  useEffect(() => {
    if (isRecording) {
      startRecording();
    } else {
      stopRecording();
    }
  }, [isRecording]);

  const startRecording = async () => {
    const canvas = getCanvas();
    const audioEl = audioRef.current;

    console.log(`üé¨ [RecordingSystem] Starting recording...`);
    console.log(`   Canvas: ${canvas ? "OK" : "MISSING"}`);
    console.log(`   Audio Element: ${audioEl ? "OK" : "MISSING"}`);

    if (!canvas || !audioEl) {
      console.error(`‚ùå [RecordingSystem] Cannot start - missing ${!canvas ? "canvas" : "audio element"}`);
      return;
    }

    console.log(`   Audio src: "${audioEl.src || "EMPTY"}"`);
    console.log(`   Audio currentSrc: "${audioEl.currentSrc || "EMPTY"}"`);
    console.log(`   Audio readyState: ${audioEl.readyState}`);

    try {
      const ctx = sonicEngine.getContext();
      if (ctx && ctx.state === "suspended") {
        console.log(`   Resuming suspended audio context...`);
        await ctx.resume();
      }

      // CRITICAL FIX: Wait for audio to be ready before recording
      if (audioEl.src || audioEl.currentSrc) {
        if (audioEl.readyState < 3) {
          console.log(
            `‚è≥ [RecordingSystem] Waiting for audio to load (readyState: ${audioEl.readyState})...`
          );

          // Try to trigger loading by playing then pausing
          try {
            const playPromise = audioEl.play();
            if (playPromise) {
              await playPromise.catch(() => {});
              audioEl.pause();
              audioEl.currentTime = 0;
            }
          } catch (e) {
            console.warn(`‚ö†Ô∏è Could not pre-play audio:`, e);
          }

          await new Promise<void>((resolve) => {
            const timeout = setTimeout(() => {
              console.warn(`‚ö†Ô∏è [RecordingSystem] Audio loading timeout - proceeding anyway`);
              resolve(); // Don't reject, just proceed
            }, 5000); // Reduced timeout to 5s

            const onCanPlay = () => {
              clearTimeout(timeout);
              audioEl.removeEventListener("canplay", onCanPlay);
              audioEl.removeEventListener("error", onError);
              audioEl.removeEventListener("loadeddata", onLoadedData);
              console.log(`‚úÖ [RecordingSystem] Audio ready! (readyState: ${audioEl.readyState})`);
              resolve();
            };

            const onLoadedData = () => {
              clearTimeout(timeout);
              audioEl.removeEventListener("canplay", onCanPlay);
              audioEl.removeEventListener("error", onError);
              audioEl.removeEventListener("loadeddata", onLoadedData);
              console.log(`‚úÖ [RecordingSystem] Audio data loaded! (readyState: ${audioEl.readyState})`);
              resolve();
            };

            const onError = (e: Event) => {
              clearTimeout(timeout);
              audioEl.removeEventListener("canplay", onCanPlay);
              audioEl.removeEventListener("error", onError);
              audioEl.removeEventListener("loadeddata", onLoadedData);
              console.error(`‚ùå [RecordingSystem] Audio load error:`, e);
              console.warn(`‚ö†Ô∏è Proceeding with recording despite audio error`);
              resolve(); // Don't reject - proceed with video-only recording
            };

            if (audioEl.readyState >= 2) {
              clearTimeout(timeout);
              resolve();
            } else {
              audioEl.addEventListener("canplay", onCanPlay);
              audioEl.addEventListener("loadeddata", onLoadedData);
              audioEl.addEventListener("error", onError);
            }
          });
        } else {
          console.log(`‚úÖ [RecordingSystem] Audio already ready (readyState: ${audioEl.readyState})`);
        }
      } else {
        console.warn(`‚ö†Ô∏è [RecordingSystem] No audio source available - recording video only`);
      }

      // CRITICAL FIX: Start playing audio BEFORE initializing audio graph
      // This ensures the audio element is actively playing when we capture its stream
      if (audioEl.src || audioEl.currentSrc) {
        console.log(`   üéµ Starting audio playback BEFORE recording...`);
        try {
          await audioEl.play();
          console.log(`   ‚úÖ Audio playing successfully (paused: ${audioEl.paused}, volume: ${audioEl.volume})`);

          // Wait a brief moment for audio to stabilize
          await new Promise(resolve => setTimeout(resolve, 100));
        } catch (e) {
          console.error(`   ‚ùå Audio playback failed:`, e);
          console.warn(`   ‚ö†Ô∏è Continuing without audio...`);
        }
      } else {
        console.warn(`   ‚ö†Ô∏è No audio source - recording video only`);
      }

      const audioStream = initAudioGraph();
      if (!audioStream) {
        console.error(`‚ùå [RecordingSystem] Could not initialize audio stream`);
        throw new Error("Could not initialize audio stream");
      }

      console.log(`   Audio stream tracks: ${audioStream.getAudioTracks().length}`);

      // ÿ¥ÿ±Ÿàÿπ ŸÖŸÑÿß€åŸÖ ÿµÿØÿß
      if (musicGainRef.current && ctx) {
        musicGainRef.current.gain.setValueAtTime(0, ctx.currentTime);
        musicGainRef.current.gain.linearRampToValueAtTime(0.8, ctx.currentTime + 1.0);
      }

      const videoStream = (canvas as any).captureStream(60);
      const audioTracks = audioStream.getAudioTracks();

      // ÿ™ÿ±⁄©€åÿ® ÿ™ÿ±⁄©‚ÄåŸáÿß€å Ÿà€åÿØÿ¶Ÿà Ÿà ÿµÿØÿß
      const tracks = [...videoStream.getVideoTracks()];
      if (audioTracks.length > 0) tracks.push(audioTracks[0]);

      const combinedStream = new MediaStream(tracks);

      const mimeType =
        ["video/mp4;codecs=avc1", "video/webm;codecs=vp9", "video/webm"].find((t) =>
          MediaRecorder.isTypeSupported(t)
        ) || "video/webm";
      currentMimeType.current = mimeType;

      const recorder = new MediaRecorder(combinedStream, {
        mimeType,
        videoBitsPerSecond: 25000000,
      });

      chunksRef.current = [];
      recorder.ondataavailable = (e) => {
        if (e.data.size > 0) chunksRef.current.push(e.data);
      };

      recorder.onstop = () => {
        const finalBlob = new Blob(chunksRef.current, { type: currentMimeType.current });
        console.log(
          `üìπ [RecordingSystem] Recording stopped! Blob size: ${(finalBlob.size / 1024 / 1024).toFixed(2)}MB`
        );
        console.log(`   Chunks collected: ${chunksRef.current.length}`);
        console.log(`   MIME type: ${currentMimeType.current}`);
        console.log(`   Calling onRecordingComplete with blob...`);

        // CRITICAL: Verify blob is valid
        if (finalBlob.size === 0) {
          console.error(`‚ùå [RecordingSystem] FATAL: Blob is empty! No data was recorded!`);
        } else {
          console.log(`‚úÖ [RecordingSystem] Blob is valid, calling callback...`);
        }

        onRecordingComplete(finalBlob);
        console.log(`‚úÖ [RecordingSystem] onRecordingComplete called successfully`);
      };

      recorder.start(1000);
      mediaRecorderRef.current = recorder;
    } catch (e) {
      console.error("Recording Engine Failure:", e);
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
      const ctx = sonicEngine.getContext();

      // ŸÅ€åÿØ-ÿßŸàÿ™ ÿ≥ÿ±€åÿπ ÿµÿØÿß ÿØÿ± ÿßŸÜÿ™Ÿáÿß€å Ÿà€åÿØÿ¶Ÿà
      if (musicGainRef.current && ctx) {
        musicGainRef.current.gain.linearRampToValueAtTime(0, ctx.currentTime + 0.5);
      }

      // ÿ™ŸàŸÇŸÅ ÿ±€å⁄©Ÿàÿ±ÿØÿ± ÿ®ÿπÿØ ÿßÿ≤ ŸÜ€åŸÖ ÿ´ÿßŸÜ€åŸá ŸÅ€åÿØ-ÿßŸàÿ™
      setTimeout(() => {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
          mediaRecorderRef.current.stop();
        }
      }, 500);
    }
  };

  return null;
};

export default RecordingSystem;
