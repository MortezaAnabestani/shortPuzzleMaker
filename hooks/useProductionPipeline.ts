import React, { useState, useCallback, useEffect, useRef } from "react";
import {
  ArtStyle,
  PieceShape,
  PieceMaterial,
  MovementType,
  PuzzleState,
  UserPreferences,
  TopicType,
  StoryArc,
} from "../types";
import {
  generateArtImage,
  YouTubeMetadata,
  getTrendingTopics,
  fetchFactNarrative,
  generateCoherentContentPackage,
  findSmartMusicByMood,
  extractCoreSubject,
} from "../services/geminiService";
import { getJalaliDate } from "../utils/dateUtils";
import { MusicTrack } from "../components/sidebar/MusicUploader";
import { VIRAL_CATEGORIES } from "../components/sidebar/VisionInput";
import { selectFreshCategory, addTopicVariation } from "../utils/contentVariety";
import { contentApi, ContentPayload } from "../services/api/contentApi";

export type PipelineStep =
  | "IDLE"
  | "SCAN"
  | "MUSIC"
  | "SYNTH"
  | "METADATA"
  | "THUMBNAIL"
  | "ANIMATE"
  | "RECORDING"
  | "PACKAGING";

export interface ProductionStep {
  id: string;
  label: string;
  status: 'pending' | 'in_progress' | 'completed' | 'error';
  details?: string;
}

const CLOUDFLARE_WORKER_URL = "https://plain-tooth-75c3.jujube-bros.workers.dev/";

interface QueueItem {
  duration: number;
  source: "BREAKING" | "VIRAL" | "NARRATIVE";
  pieceCount: number;
}

/**
 * ØªØµØ§Ø¯ÙÛŒâ€ŒØ³Ø§Ø²ÛŒ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¨ØµØ±ÛŒ Ù…Ø·Ø§Ø¨Ù‚ AUTO_PILOT_STRATEGY.md
 */
const randomizeVisualParameters = () => {
  const artStyles = Object.values(ArtStyle);
  const movements = Object.values(MovementType);
  const materials = Object.values(PieceMaterial);
  const shapes = Object.values(PieceShape);

  const randomStyle = artStyles[Math.floor(Math.random() * artStyles.length)];
  const randomMovement = movements[Math.floor(Math.random() * movements.length)];
  const randomMaterial = materials[Math.floor(Math.random() * materials.length)];
  const randomShape = shapes[Math.floor(Math.random() * shapes.length)];

  console.log(`ğŸ­ [VARIETY] Style: ${randomStyle}, Movement: ${randomMovement}, Material: ${randomMaterial}, Shape: ${randomShape}`);

  return { randomStyle, randomMovement, randomMaterial, randomShape };
};

/**
 * Ø§Ù†ØªØ®Ø§Ø¨ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ: Manual â†’ Backend â†’ AI
 */
interface SmartMusicSelectionParams {
  musicTracks: MusicTrack[];
  queueIndex: number;
  musicMood: any;
  topic: string;
  fetchAudioBlob: (url: string) => Promise<string | null>;
  onAddCloudTrack: (url: string, title: string) => void;
  setActiveTrackName: (name: string | null) => void;
  audioRef: React.RefObject<HTMLAudioElement | null>;
}

const selectSmartMusic = async (params: SmartMusicSelectionParams): Promise<{ source: string; title: string } | null> => {
  const { musicTracks, queueIndex, musicMood, topic, fetchAudioBlob, onAddCloudTrack, setActiveTrackName, audioRef } = params;

  // Priority 1: Manual tracks
  if (musicTracks.length > 0) {
    const selectedTrack = musicTracks[queueIndex % musicTracks.length];
    console.log(`ğŸµ [MUSIC] Source: Manual (${queueIndex % musicTracks.length + 1}/${musicTracks.length}), Track: ${selectedTrack.name}`);

    // Load music to audioRef
    if (audioRef.current) {
      audioRef.current.src = selectedTrack.url;
      audioRef.current.load();
      console.log(`   ğŸ”Š Music loaded to audio player`);
    }

    setActiveTrackName(selectedTrack.name);
    return { source: 'Manual Upload', title: selectedTrack.name };
  }

  // Priority 2 & 3: Backend (Ø¯Ø± smartFetcher Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÛŒâ€ŒØ´ÙˆØ¯) ÛŒØ§ AI
  console.log(`ğŸµ [MUSIC] No manual tracks, using smartFetcher...`);
  const { smartFetcher } = await import('../services/smartFetcher');
  const trackData = await smartFetcher.fetchMusic(musicMood, topic);

  if (trackData && trackData.url) {
    const blobUrl = await fetchAudioBlob(trackData.url);
    if (blobUrl) {
      onAddCloudTrack(blobUrl, trackData.title);
      setActiveTrackName(trackData.title);

      // Load music to audioRef
      if (audioRef.current) {
        audioRef.current.src = blobUrl;
        audioRef.current.load();
        console.log(`   ğŸ”Š Music loaded to audio player`);
      }

      console.log(`ğŸµ [MUSIC] Source: ${trackData.source}, Track: ${trackData.title}`);
      return { source: trackData.source, title: trackData.title };
    }
  }

  console.warn(`âš ï¸ [MUSIC] No music found`);
  return null;
};

export const useProductionPipeline = (
  preferences: UserPreferences,
  setPreferences: React.Dispatch<React.SetStateAction<UserPreferences>>,
  musicTracks: MusicTrack[],
  selectedTrackId: string | null,
  setActiveTrackName: (name: string | null) => void,
  onAddCloudTrack: (url: string, title: string) => void,
  audioRef: React.RefObject<HTMLAudioElement | null>
) => {
  const [state, setState] = useState<
    PuzzleState & {
      audioError: boolean;
      isAutoMode: boolean;
      pipelineStep: PipelineStep;
      isFullPackage: boolean;
      queue: QueueItem[];
      currentQueueIdx: number;
      docSnippets: string[];
      storyArc: StoryArc | null;
      productionSteps: ProductionStep[];
    }
  >({
    isGenerating: false,
    isSolving: false,
    isRecording: false,
    progress: 0,
    imageUrl: null,
    error: null,
    audioError: false,
    isAutoMode: false,
    pipelineStep: "IDLE",
    isFullPackage: false,
    queue: [],
    currentQueueIdx: -1,
    docSnippets: [],
    storyArc: null,
    productionSteps: [],
  });

  const [metadata, setMetadata] = useState<YouTubeMetadata | null>(null);
  const [isMetadataLoading, setIsMetadataLoading] = useState(false);
  const [thumbnailDataUrl, setThumbnailDataUrl] = useState<string | null>(null);
  const [lastVideoBlob, setLastVideoBlob] = useState<Blob | null>(null);
  const [currentCoreSubject, setCurrentCoreSubject] = useState<string | null>(null);
  const [currentVisualPrompt, setCurrentVisualPrompt] = useState<string | null>(null);
  const isExportingRef = useRef(false);

  // Helper function to update production steps
  const updateProductionStep = useCallback((stepId: string, status: ProductionStep['status'], details?: string) => {
    setState(prev => {
      const existingStepIndex = prev.productionSteps.findIndex(s => s.id === stepId);

      if (existingStepIndex >= 0) {
        // Update existing step
        const updatedSteps = [...prev.productionSteps];
        updatedSteps[existingStepIndex] = {
          ...updatedSteps[existingStepIndex],
          status,
          details: details || updatedSteps[existingStepIndex].details,
        };
        return { ...prev, productionSteps: updatedSteps };
      } else {
        // Add new step
        return {
          ...prev,
          productionSteps: [
            ...prev.productionSteps,
            { id: stepId, label: stepId, status, details },
          ],
        };
      }
    });
  }, []);

  // Initialize production steps
  const initializeProductionSteps = useCallback(() => {
    const steps: ProductionStep[] = [
      { id: 'ğŸ“Š SCAN', label: 'Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¹ Ù…Ø­ØªÙˆØ§', status: 'pending' },
      { id: 'ğŸ”Š SOUND FX', label: 'ØªØµØ§Ø¯ÙÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø§ÙÚ©Øªâ€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ', status: 'pending' },
      { id: 'ğŸ­ VARIETY', label: 'ØªØµØ§Ø¯ÙÛŒâ€ŒØ³Ø§Ø²ÛŒ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¨ØµØ±ÛŒ', status: 'pending' },
      { id: 'ğŸ” VALIDATION', label: 'Ø¨Ø±Ø±Ø³ÛŒ ØªØ´Ø§Ø¨Ù‡ Ù…Ø­ØªÙˆØ§', status: 'pending' },
      { id: 'ğŸµ MUSIC', label: 'Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÙˆØ³ÛŒÙ‚ÛŒ', status: 'pending' },
      { id: 'ğŸ¨ GENERATE', label: 'ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ùˆ Ø¯Ø§Ø³ØªØ§Ù†', status: 'pending' },
      { id: 'ğŸ“ METADATA', label: 'ØªÙˆÙ„ÛŒØ¯ Ù…ØªØ§Ø¯ÛŒØªØ§', status: 'pending' },
      { id: 'ğŸ–¼ï¸ THUMBNAIL', label: 'Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªØ§Ù…Ø¨Ù†ÛŒÙ„', status: 'pending' },
      { id: 'ğŸ¬ ANIMATE', label: 'Ø´Ø±ÙˆØ¹ Ø§Ù†ÛŒÙ…ÛŒØ´Ù† Ù¾Ø§Ø²Ù„', status: 'pending' },
      { id: 'ğŸ¥ RECORD', label: 'Ø¶Ø¨Ø· ÙˆÛŒØ¯Ø¦Ùˆ', status: 'pending' },
      { id: 'ğŸ“¦ PACKAGE', label: 'Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯', status: 'pending' },
    ];
    setState(prev => ({ ...prev, productionSteps: steps }));
  }, []);

  const downloadFile = (name: string, blob: Blob) => {
    const url = URL.createObjectURL(blob);
    const link = document.createElement("a");
    link.href = url;
    link.download = name;
    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);
    setTimeout(() => URL.revokeObjectURL(url), 3000);
  };

  const fetchAudioBlob = async (url: string): Promise<string | null> => {
    const proxies = [
      { url: `${CLOUDFLARE_WORKER_URL}?url=${encodeURIComponent(url)}` },
      { url: `https://api.allorigins.win/raw?url=${encodeURIComponent(url)}` },
    ];
    for (const p of proxies) {
      try {
        const res = await fetch(p.url);
        if (res.ok) {
          const blob = await res.blob();
          return URL.createObjectURL(blob);
        }
      } catch (e) {
        console.warn("Proxy fail:", p.url);
      }
    }
    return null;
  };

  const executePackaging = useCallback(
    async (videoBlob: Blob) => {
      console.log(`ğŸ“¦ [Packaging] executePackaging called`);
      console.log(`   isExportingRef: ${isExportingRef.current}`);
      console.log(`   videoBlob size: ${(videoBlob.size / 1024 / 1024).toFixed(2)}MB`);

      if (isExportingRef.current) {
        console.log(`â¸ï¸ [Packaging] Already exporting, skipping...`);
        return;
      }
      isExportingRef.current = true;

      const jalali = getJalaliDate();
      const cleanTitle = (metadata?.title || "Studio_Project").replace(/[\\/:*?"<>|]/g, "").slice(0, 50);
      const baseFileName = `${jalali}_${cleanTitle}`;

      // Step 9: PACKAGE - Export and save
      updateProductionStep('ğŸ“¦ PACKAGE', 'in_progress', 'Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ...');
      console.log(`ğŸ“¥ [Packaging] Starting downloads with base filename: ${baseFileName}`);

      try {
        console.log(`   1ï¸âƒ£ Downloading video...`);
        downloadFile(`${baseFileName}_Video.${videoBlob.type.includes("mp4") ? "mp4" : "webm"}`, videoBlob);

        if (metadata) {
          console.log(`   2ï¸âƒ£ Downloading metadata...`);
          await new Promise((r) => setTimeout(r, 1500));
          downloadFile(
            `${baseFileName}_Metadata.txt`,
            new Blob([`TITLE: ${metadata.title}\n\nDESC: ${metadata.description}`], { type: "text/plain" })
          );
        }

        if (thumbnailDataUrl) {
          console.log(`   3ï¸âƒ£ Downloading thumbnail...`);
          await new Promise((r) => setTimeout(r, 1500));
          const res = await fetch(thumbnailDataUrl);
          downloadFile(`${baseFileName}_Thumbnail.jpg`, await res.blob());
        }

        console.log(`âœ… [Packaging] All downloads completed!`);

        // Save content to backend database after successful download
        console.log(`ğŸ” [Packaging] Checking requirements for database save...`);
        console.log(`   currentCoreSubject: ${currentCoreSubject ? "âœ… EXISTS" : "âŒ MISSING"}`);
        console.log(`   currentVisualPrompt: ${currentVisualPrompt ? "âœ… EXISTS" : "âŒ MISSING"}`);
        console.log(`   metadata: ${metadata ? "âœ… EXISTS" : "âŒ MISSING"}`);

        if (currentCoreSubject && currentVisualPrompt && metadata) {
          console.log(`ğŸ’¾ [API] All requirements met! Saving content to database...`);

          const payload: ContentPayload = {
            jalaliDate: jalali,
            puzzleCard: {
              category: preferences.topicCategory || "Unknown",
              narrativeLens: preferences.narrativeLens,
              artStyle: preferences.style,
              pieceCount: preferences.pieceCount,
              duration: preferences.durationMinutes,
              shape: preferences.shape,
              material: preferences.material,
              movement: preferences.movement,
            },
            story: {
              coreSubject: currentCoreSubject,
              visualPrompt: currentVisualPrompt,
              hook: state.storyArc?.hook,
              buildup: state.storyArc?.buildup,
              climax: state.storyArc?.climax,
              reveal: state.storyArc?.reveal,
            },
            metadata: {
              title: metadata.title,
              description: metadata.description,
              tags: metadata.tags,
              hashtags: metadata.hashtags,
            },
            files: {
              videoFilename: `${baseFileName}_Video.${videoBlob.type.includes("mp4") ? "mp4" : "webm"}`,
              thumbnailFilename: thumbnailDataUrl ? `${baseFileName}_Thumbnail.jpg` : undefined,
              videoSizeMB: Number((videoBlob.size / 1024 / 1024).toFixed(2)),
            },
            analysis: {
              isUnique: true, // Passed validation
              generationAttempts: 1,
            },
          };

          const saveResult = await contentApi.saveContent(payload);

          if (saveResult.success) {
            console.log(`âœ… [API] Content saved to database successfully!`);
            console.log(`   Database ID: ${saveResult.data?._id}`);
            console.log(`ğŸ“¦ [PACKAGE] Saved: ${payload.files.videoFilename}, DB ID: ${saveResult.data?._id}`);
            updateProductionStep('ğŸ“¦ PACKAGE', 'completed', `Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ - DB ID: ${saveResult.data?._id?.substring(0, 8)}...`);
          } else {
            console.error(`âŒ [API] Failed to save content: ${saveResult.error}`);
            console.warn(`âš ï¸ [API] Content was downloaded but not saved to database`);
            updateProductionStep('ğŸ“¦ PACKAGE', 'completed', 'Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ - Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³');
          }

          // Clear after recording
          setCurrentCoreSubject(null);
          setCurrentVisualPrompt(null);
        } else {
          console.log(`â­ï¸ [API] Skipping database save (missing required data)`);
          updateProductionStep('ğŸ“¦ PACKAGE', 'completed', 'Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ - Ø¨Ø¯ÙˆÙ† Ø°Ø®ÛŒØ±Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³');
        }
      } finally {
        setLastVideoBlob(null);
        isExportingRef.current = false;

        // Log completion
        const currentIdx = state.currentQueueIdx;
        console.log(`âœ… [COMPLETE] Video ${currentIdx + 1} finished successfully`);

        setTimeout(() => {
          setState((prev) => {
            const nextIdx = prev.currentQueueIdx + 1;
            const hasNext = prev.isFullPackage && nextIdx < prev.queue.length;

            if (hasNext) {
              console.log(`\nâ¡ï¸  [AutoPilot] Moving to next video (${nextIdx + 1}/${prev.queue.length})\n`);
            } else {
              console.log(`\nğŸ [AutoPilot] All videos completed! Auto-Pilot finished.\n`);
            }

            return {
              ...prev,
              currentQueueIdx: hasNext ? nextIdx : -1,
              pipelineStep: "IDLE",
              isAutoMode: hasNext,
              isFullPackage: hasNext,
              isSolving: false,
              isRecording: false,
              progress: 0,
              imageUrl: hasNext ? prev.imageUrl : null,
            };
          });
        }, 2500);
      }
    },
    [metadata, thumbnailDataUrl]
  );

  useEffect(() => {
    if (state.pipelineStep === "PACKAGING" && lastVideoBlob && !isExportingRef.current) {
      executePackaging(lastVideoBlob);
    }
  }, [state.pipelineStep, lastVideoBlob, executePackaging]);

  const processPipelineItem = useCallback(
    async (item: QueueItem, isManualOverride: boolean = false) => {
      setState((s) => ({
        ...s,
        pipelineStep: "SCAN",
        isGenerating: true,
        error: null,
        imageUrl: isManualOverride ? s.imageUrl : null,
        progress: 0,
        storyArc: null,
      }));

      setLastVideoBlob(null);
      setMetadata(null);
      setThumbnailDataUrl(null);

      try {
        let sourceSubject = preferences.subject;
        let activeTopicType = TopicType.MANUAL;
        let categoryLabel = "Custom";

        if (!isManualOverride && state.isAutoMode) {
          // ğŸ¬ [AutoPilot] Starting video logging
          console.log(`ğŸ¬ [AutoPilot] Starting video ${state.currentQueueIdx + 1}/${state.queue.length}`);

          // Initialize production steps for this video
          initializeProductionSteps();

          // Step 1: SCAN
          updateProductionStep('ğŸ“Š SCAN', 'in_progress');
          console.log(`ğŸ“Š [SCAN] Content Type: ${item.source}`);
          updateProductionStep('ğŸ“Š SCAN', 'completed', `Ù†ÙˆØ¹: ${item.source}, Ù…Ø¯Øª: ${item.duration * 60}s, Ù‚Ø·Ø¹Ø§Øª: ${item.pieceCount}`);

          // Step 2: Sound FX
          updateProductionStep('ğŸ”Š SOUND FX', 'in_progress');
          console.log(`ğŸ”Š [SOUND FX] Randomizing all sound effects...`);
          const { soundRandomizer } = await import('../services/soundRandomizer');
          const { useBackendMode } = await import('../contexts/BackendModeContext');
          // We can't use the hook here, so we check smartFetcher's mode instead
          const { smartFetcher } = await import('../services/smartFetcher');
          const preferBackend = smartFetcher.isBackendEnabled();
          await soundRandomizer.randomizeAllSounds(preferBackend);
          console.log(`ğŸ”Š [SOUND FX] Randomized: SNAP, MOVE, WAVE, DESTRUCT`);
          updateProductionStep('ğŸ”Š SOUND FX', 'completed', 'SNAP, MOVE, WAVE, DESTRUCT');

          if (item.source === "VIRAL") {
            let contentPackage;
            let coreSubject;
            let attempts = 0;
            const maxAttempts = 5;

            // Step 3: VALIDATION - Uniqueness check
            updateProductionStep('ğŸ” VALIDATION', 'in_progress');

            // Validation loop: Keep generating until we find unique content
            while (attempts < maxAttempts) {
              attempts++;

              // Select a fresh category that hasn't been used recently
              const randomNiche = selectFreshCategory(VIRAL_CATEGORIES, 5);

              // Add unique variation to prevent repetitive prompts
              const variedTopic = addTopicVariation(randomNiche.topic);

              console.log(
                `\nğŸ¯ Attempt ${attempts}/${maxAttempts}: Generating content for "${randomNiche.label}"`
              );
              console.log(`ğŸ¨ Variation: ${variedTopic.substring(0, 100)}...`);

              // Generate content package
              contentPackage = await generateCoherentContentPackage(variedTopic, randomNiche.label);

              // Extract core subject for similarity checking
              coreSubject = await extractCoreSubject(
                contentPackage.visualPrompt,
                contentPackage.storyArc,
                randomNiche.label
              );

              // Check similarity via backend API
              console.log(`ğŸ” [API] Checking content similarity with backend...`);
              const similarityResult = await contentApi.checkSimilarity(coreSubject);

              if (similarityResult.success && similarityResult.data) {
                const isSimilar = similarityResult.data.isSimilar;
                const score = similarityResult.data.similarityScore;

                if (!isSimilar) {
                  console.log(`âœ… Content approved as unique! Proceeding with generation.`);
                  console.log(`ğŸ” [VALIDATION] Similarity Score: ${score} (UNIQUE)`);
                  const scoreText = score !== undefined ? score.toFixed(2) : 'N/A';
                  updateProductionStep('ğŸ” VALIDATION', 'completed', `Ø§Ù…ØªÛŒØ§Ø²: ${scoreText} - Ù…Ø­ØªÙˆØ§ÛŒ Ù…Ù†Ø­ØµØ±Ø¨Ù‡â€ŒÙØ±Ø¯`);
                  break; // Content is unique, exit loop
                } else {
                  console.log(`âŒ Content rejected as too similar (score: ${score})`);
                  console.log(`ğŸ” [VALIDATION] Similarity Score: ${score} (DUPLICATE)`);
                  if (similarityResult.data.matchedContents?.length > 0) {
                    console.log(`   Matched: ${similarityResult.data.matchedContents.map((m: any) => m.title).join(", ")}`);
                  }

                  if (attempts < maxAttempts) {
                    console.log(`   ğŸ”„ Regenerating with different parameters...\n`);
                    const scoreText = score !== undefined ? score.toFixed(2) : 'N/A';
                    updateProductionStep('ğŸ” VALIDATION', 'in_progress', `Ø§Ù…ØªÛŒØ§Ø²: ${scoreText} - ØªÙ„Ø§Ø´ ${attempts}/${maxAttempts}`);
                  }
                }
              } else {
                // If API check fails, log warning but continue (don't crash the pipeline)
                console.warn(`âš ï¸ [API] Similarity check failed: ${similarityResult.error}`);
                console.log(`   Proceeding with content generation (assuming unique)...`);
                updateProductionStep('ğŸ” VALIDATION', 'completed', 'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ - Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø§ ÙØ±Ø¶ Ù…Ù†Ø­ØµØ±Ø¨Ù‡â€ŒÙØ±Ø¯ Ø¨ÙˆØ¯Ù†');
                break;
              }
            }

            if (attempts >= maxAttempts) {
              console.warn(`âš ï¸ Max attempts reached. Using last generated content despite similarity.`);
              updateProductionStep('ğŸ” VALIDATION', 'completed', `Ø­Ø¯Ø§Ú©Ø«Ø± ØªÙ„Ø§Ø´ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† Ù…Ø­ØªÙˆØ§`);
            }

            // Store core subject and visual prompt for later recording
            setCurrentCoreSubject(coreSubject);
            setCurrentVisualPrompt(contentPackage.visualPrompt);

            sourceSubject = contentPackage.visualPrompt;
            activeTopicType = TopicType.VIRAL;
            categoryLabel = contentPackage.theme.category;

            // Step 3: VARIETY - Randomize Visual Parameters
            updateProductionStep('ğŸ­ VARIETY', 'in_progress');
            const { randomStyle, randomMovement, randomMaterial, randomShape } = randomizeVisualParameters();
            console.log(`ğŸ­ [VARIETY] Style: ${randomStyle}, Movement: ${randomMovement}, Material: ${randomMaterial}, Shape: ${randomShape}`);
            updateProductionStep('ğŸ­ VARIETY', 'completed', `Ø³Ø¨Ú©: ${randomStyle}, Ø­Ø±Ú©Øª: ${randomMovement}, Ù…Ø§Ø¯Ù‡: ${randomMaterial}, Ø´Ú©Ù„: ${randomShape}`);

            // Step 4: MUSIC - Smart Music Selection
            setState((s) => ({ ...s, pipelineStep: "MUSIC" }));
            updateProductionStep('ğŸµ MUSIC', 'in_progress');
            const musicResult = await selectSmartMusic({
              musicTracks,
              queueIndex: state.currentQueueIdx,
              musicMood: contentPackage.theme.musicMood,
              topic: sourceSubject,
              fetchAudioBlob,
              onAddCloudTrack,
              setActiveTrackName,
              audioRef,
            });
            if (musicResult) {
              console.log(`ğŸµ [MUSIC] Selected: ${musicResult.title} from ${musicResult.source}`);
              const titlePreview = musicResult.title.length > 40 ? musicResult.title.substring(0, 40) + '...' : musicResult.title;
              updateProductionStep('ğŸµ MUSIC', 'completed', `Ù…Ù†Ø¨Ø¹: ${musicResult.source}, Ù‚Ø·Ø¹Ù‡: ${titlePreview}`);
            } else {
              updateProductionStep('ğŸµ MUSIC', 'completed', 'Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯ - Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÙˆÙ† Ù…ÙˆØ³ÛŒÙ‚ÛŒ');
            }

            // Step 5: GENERATE - Create Visual Content
            setState((s) => ({ ...s, pipelineStep: "SYNTH" }));
            updateProductionStep('ğŸ¨ GENERATE', 'in_progress');
            const art = await generateArtImage(randomStyle, contentPackage.visualPrompt);
            console.log(`ğŸ¨ [GENERATE] Image: ${art.imageUrl?.substring(0, 50)}..., Story: ${contentPackage.storyArc.hook}`);
            const hookPreview = contentPackage.storyArc.hook.length > 50 ? contentPackage.storyArc.hook.substring(0, 50) + '...' : contentPackage.storyArc.hook;
            updateProductionStep('ğŸ¨ GENERATE', 'completed', `ØªØµÙˆÛŒØ± ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯ - Ø¯Ø§Ø³ØªØ§Ù†: ${hookPreview}`);

            setPreferences((p) => ({
              ...p,
              subject: sourceSubject,
              style: randomStyle,
              movement: randomMovement,
              material: randomMaterial,
              shape: randomShape,
              pieceCount: item.pieceCount,
              durationMinutes: item.duration,
              topicType: activeTopicType,
              topicCategory: categoryLabel,
              narrativeLens: contentPackage.theme.narrativeLens,
            }));

            setState((s) => ({
              ...s,
              imageUrl: art.imageUrl,
              storyArc: contentPackage.storyArc,
              docSnippets: [],
              isGenerating: false,
              pipelineStep: "METADATA",
            }));

            // Step 6: METADATA - Generate metadata
            updateProductionStep('ğŸ“‹ METADATA', 'in_progress');
            setIsMetadataLoading(true);
            setMetadata(contentPackage.metadata);
            setIsMetadataLoading(false);
            console.log(`ğŸ“‹ [METADATA] Title: ${contentPackage.metadata?.title}`);
            const metadataTitle = contentPackage.metadata?.title || 'Ù†Ø§Ù…Ø´Ø®Øµ';
            const titlePreview = metadataTitle.length > 50 ? metadataTitle.substring(0, 50) + '...' : metadataTitle;
            updateProductionStep('ğŸ“‹ METADATA', 'completed', `Ø¹Ù†ÙˆØ§Ù†: ${titlePreview}`);

            // Step 7: THUMBNAIL - Prepare thumbnail
            setState((s) => ({ ...s, pipelineStep: "THUMBNAIL" }));
            updateProductionStep('ğŸ–¼ï¸ THUMBNAIL', 'in_progress');
            console.log(`ğŸ–¼ï¸ [THUMBNAIL] Preparing thumbnail generation...`);
            updateProductionStep('ğŸ–¼ï¸ THUMBNAIL', 'completed', 'Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØªØ§Ù…Ø¨Ù†ÛŒÙ„');

            if (state.isAutoMode) {
              // Step 8: ANIMATE - Start animation
              updateProductionStep('ğŸ¬ ANIMATE', 'in_progress', 'Ø§Ù†ØªØ¸Ø§Ø± 10 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ú¯ÛŒ Ú©Ø§Ù…Ù„ Ù…Ø±ÙˆØ±Ú¯Ø±...');
              console.log(`â¸ï¸ [AutoPilot] Waiting 10 seconds for browser to prepare...`);
              setTimeout(
                () => {
                  setState((s) => ({ ...s, isSolving: true, isRecording: true, pipelineStep: "RECORDING" }));
                  updateProductionStep('ğŸ¬ ANIMATE', 'completed', 'Ø§Ù†ÛŒÙ…ÛŒØ´Ù† Ø¢ØºØ§Ø² Ø´Ø¯');
                  updateProductionStep('ğŸ¥ RECORD', 'in_progress', 'Ø¯Ø± Ø­Ø§Ù„ Ø¶Ø¨Ø· ÙˆÛŒØ¯Ø¦Ùˆ...');
                },
                10000
              );
            } else {
              setState((s) => ({ ...s, pipelineStep: "IDLE" }));
            }
          } else if (item.source === "NARRATIVE") {
            // Use new Coherent Content Package for NARRATIVE mode too
            const randomNiche = VIRAL_CATEGORIES[Math.floor(Math.random() * VIRAL_CATEGORIES.length)];

            console.log(`ğŸ¯ NARRATIVE Mode: Generating coherent package for "${randomNiche.label}"`);
            const contentPackage = await generateCoherentContentPackage(randomNiche.topic, randomNiche.label);

            // Extract core subject for database save
            const coreSubject = await extractCoreSubject(
              contentPackage.visualPrompt,
              contentPackage.storyArc,
              randomNiche.label
            );

            // Store for later database save
            setCurrentCoreSubject(coreSubject);
            setCurrentVisualPrompt(contentPackage.visualPrompt);

            sourceSubject = contentPackage.visualPrompt;
            activeTopicType = TopicType.NARRATIVE;
            categoryLabel = contentPackage.theme.category;

            // NARRATIVE skips VALIDATION step (no similarity check needed for historical content)
            updateProductionStep('ğŸ” VALIDATION', 'completed', 'Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ - Ù…Ø­ØªÙˆØ§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ');

            // Step 3: VARIETY - Randomize Visual Parameters
            updateProductionStep('ğŸ­ VARIETY', 'in_progress');
            const narrativeVisual = randomizeVisualParameters();
            console.log(`ğŸ­ [VARIETY] Style: ${narrativeVisual.randomStyle}, Movement: ${narrativeVisual.randomMovement}`);
            updateProductionStep('ğŸ­ VARIETY', 'completed', `Ø³Ø¨Ú©: ${narrativeVisual.randomStyle}, Ø­Ø±Ú©Øª: ${narrativeVisual.randomMovement}, Ù…Ø§Ø¯Ù‡: ${narrativeVisual.randomMaterial}, Ø´Ú©Ù„: ${narrativeVisual.randomShape}`);

            // Step 4: MUSIC - Smart Music Selection
            setState((s) => ({ ...s, pipelineStep: "MUSIC" }));
            updateProductionStep('ğŸµ MUSIC', 'in_progress');
            const narrativeMusicResult = await selectSmartMusic({
              musicTracks,
              queueIndex: state.currentQueueIdx,
              musicMood: contentPackage.theme.musicMood,
              topic: sourceSubject,
              fetchAudioBlob,
              onAddCloudTrack,
              setActiveTrackName,
              audioRef,
            });
            if (narrativeMusicResult) {
              console.log(`ğŸµ [MUSIC] Selected: ${narrativeMusicResult.title} from ${narrativeMusicResult.source}`);
              const musicTitlePreview = narrativeMusicResult.title.length > 40 ? narrativeMusicResult.title.substring(0, 40) + '...' : narrativeMusicResult.title;
              updateProductionStep('ğŸµ MUSIC', 'completed', `Ù…Ù†Ø¨Ø¹: ${narrativeMusicResult.source}, Ù‚Ø·Ø¹Ù‡: ${musicTitlePreview}`);
            } else {
              updateProductionStep('ğŸµ MUSIC', 'completed', 'Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯ - Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÙˆÙ† Ù…ÙˆØ³ÛŒÙ‚ÛŒ');
            }

            // Step 5: GENERATE - Create Visual Content
            setState((s) => ({ ...s, pipelineStep: "SYNTH" }));
            updateProductionStep('ğŸ¨ GENERATE', 'in_progress');
            const art = await generateArtImage(narrativeVisual.randomStyle, contentPackage.visualPrompt);
            console.log(`ğŸ¨ [GENERATE] Image: ${art.imageUrl?.substring(0, 50)}..., Story: ${contentPackage.storyArc.hook}`);
            const narrativeHookPreview = contentPackage.storyArc.hook.length > 50 ? contentPackage.storyArc.hook.substring(0, 50) + '...' : contentPackage.storyArc.hook;
            updateProductionStep('ğŸ¨ GENERATE', 'completed', `ØªØµÙˆÛŒØ± ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯ - Ø¯Ø§Ø³ØªØ§Ù†: ${narrativeHookPreview}`);

            setPreferences((p) => ({
              ...p,
              subject: sourceSubject,
              style: narrativeVisual.randomStyle,
              movement: narrativeVisual.randomMovement,
              material: narrativeVisual.randomMaterial,
              shape: narrativeVisual.randomShape,
              pieceCount: item.pieceCount,
              durationMinutes: item.duration,
              topicType: activeTopicType,
              topicCategory: categoryLabel,
              narrativeLens: contentPackage.theme.narrativeLens,
            }));

            setState((s) => ({
              ...s,
              imageUrl: art.imageUrl,
              storyArc: contentPackage.storyArc,
              docSnippets: [],
              isGenerating: false,
              pipelineStep: "METADATA",
            }));

            // Step 6: METADATA - Generate metadata
            updateProductionStep('ğŸ“‹ METADATA', 'in_progress');
            setIsMetadataLoading(true);
            setMetadata(contentPackage.metadata);
            setIsMetadataLoading(false);
            console.log(`ğŸ“‹ [METADATA] Title: ${contentPackage.metadata?.title}`);
            const metadataTitle = contentPackage.metadata?.title || 'Ù†Ø§Ù…Ø´Ø®Øµ';
            const titlePreview = metadataTitle.length > 50 ? metadataTitle.substring(0, 50) + '...' : metadataTitle;
            updateProductionStep('ğŸ“‹ METADATA', 'completed', `Ø¹Ù†ÙˆØ§Ù†: ${titlePreview}`);

            // Step 7: THUMBNAIL - Prepare thumbnail
            setState((s) => ({ ...s, pipelineStep: "THUMBNAIL" }));
            updateProductionStep('ğŸ–¼ï¸ THUMBNAIL', 'in_progress');
            console.log(`ğŸ–¼ï¸ [THUMBNAIL] Preparing thumbnail generation...`);
            updateProductionStep('ğŸ–¼ï¸ THUMBNAIL', 'completed', 'Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØªØ§Ù…Ø¨Ù†ÛŒÙ„');

            if (state.isAutoMode) {
              // Step 8: ANIMATE - Start animation
              updateProductionStep('ğŸ¬ ANIMATE', 'in_progress', 'Ø§Ù†ØªØ¸Ø§Ø± 10 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ú¯ÛŒ Ú©Ø§Ù…Ù„ Ù…Ø±ÙˆØ±Ú¯Ø±...');
              console.log(`â¸ï¸ [AutoPilot] Waiting 10 seconds for browser to prepare...`);
              setTimeout(
                () => {
                  setState((s) => ({ ...s, isSolving: true, isRecording: true, pipelineStep: "RECORDING" }));
                  updateProductionStep('ğŸ¬ ANIMATE', 'completed', 'Ø§Ù†ÛŒÙ…ÛŒØ´Ù† Ø¢ØºØ§Ø² Ø´Ø¯');
                  updateProductionStep('ğŸ¥ RECORD', 'in_progress', 'Ø¯Ø± Ø­Ø§Ù„ Ø¶Ø¨Ø· ÙˆÛŒØ¯Ø¦Ùˆ...');
                },
                10000
              );
            } else {
              setState((s) => ({ ...s, pipelineStep: "IDLE" }));
            }
          } else if (item.source === "BREAKING") {
            // Breaking News Mode: AI Search for trending topics
            console.log(`ğŸ¯ BREAKING Mode: Fetching trending topics via AI Search...`);

            let contentPackage;
            let coreSubject;
            let attempts = 0;
            const maxAttempts = 5;

            // Step 3: VALIDATION - Uniqueness check with trending topics
            updateProductionStep('ğŸ” VALIDATION', 'in_progress');

            // Validation loop with trending topics
            while (attempts < maxAttempts) {
              attempts++;

              // Fetch trending topics
              const trendingTopics = await getTrendingTopics();
              const randomTopic = trendingTopics[Math.floor(Math.random() * trendingTopics.length)];

              console.log(
                `\nğŸ¯ Attempt ${attempts}/${maxAttempts}: Generating breaking news content`
              );
              console.log(`ğŸ“° Topic: ${randomTopic}`);

              // Generate content package
              contentPackage = await generateCoherentContentPackage(randomTopic, "Breaking News");

              // Extract core subject for similarity checking
              coreSubject = await extractCoreSubject(
                contentPackage.visualPrompt,
                contentPackage.storyArc,
                "Breaking News"
              );

              // Check similarity via backend API
              console.log(`ğŸ” [API] Checking content similarity with backend...`);
              const similarityResult = await contentApi.checkSimilarity(coreSubject);

              if (similarityResult.success && similarityResult.data) {
                const isSimilar = similarityResult.data.isSimilar;
                const score = similarityResult.data.similarityScore;

                if (!isSimilar) {
                  console.log(`âœ… Content approved as unique! Proceeding with generation.`);
                  console.log(`ğŸ” [VALIDATION] Similarity Score: ${score} (UNIQUE)`);
                  const scoreText = score !== undefined ? score.toFixed(2) : 'N/A';
                  updateProductionStep('ğŸ” VALIDATION', 'completed', `Ø§Ù…ØªÛŒØ§Ø²: ${scoreText} - Ø®Ø¨Ø± Ù…Ù†Ø­ØµØ±Ø¨Ù‡â€ŒÙØ±Ø¯`);
                  break;
                } else {
                  console.log(`âŒ Content rejected as too similar (score: ${score})`);
                  if (attempts < maxAttempts) {
                    console.log(`   ğŸ”„ Regenerating with different topic...\n`);
                    const scoreText = score !== undefined ? score.toFixed(2) : 'N/A';
                    updateProductionStep('ğŸ” VALIDATION', 'in_progress', `Ø§Ù…ØªÛŒØ§Ø²: ${scoreText} - ØªÙ„Ø§Ø´ ${attempts}/${maxAttempts}`);
                  }
                }
              } else {
                console.warn(`âš ï¸ [API] Similarity check failed: ${similarityResult.error}`);
                console.log(`   Proceeding with content generation (assuming unique)...`);
                updateProductionStep('ğŸ” VALIDATION', 'completed', 'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ - Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø§ ÙØ±Ø¶ Ù…Ù†Ø­ØµØ±Ø¨Ù‡â€ŒÙØ±Ø¯ Ø¨ÙˆØ¯Ù†');
                break;
              }
            }

            if (attempts >= maxAttempts) {
              console.warn(`âš ï¸ Max attempts reached. Using last generated content despite similarity.`);
              updateProductionStep('ğŸ” VALIDATION', 'completed', `Ø­Ø¯Ø§Ú©Ø«Ø± ØªÙ„Ø§Ø´ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† Ø®Ø¨Ø±`);
            }

            // Store core subject and visual prompt
            setCurrentCoreSubject(coreSubject);
            setCurrentVisualPrompt(contentPackage.visualPrompt);

            sourceSubject = contentPackage.visualPrompt;
            activeTopicType = TopicType.BREAKING;
            categoryLabel = "Breaking News";

            // Step 3: VARIETY - Randomize Visual Parameters
            updateProductionStep('ğŸ­ VARIETY', 'in_progress');
            const breakingVisual = randomizeVisualParameters();
            console.log(`ğŸ­ [VARIETY] Style: ${breakingVisual.randomStyle}, Movement: ${breakingVisual.randomMovement}`);
            updateProductionStep('ğŸ­ VARIETY', 'completed', `Ø³Ø¨Ú©: ${breakingVisual.randomStyle}, Ø­Ø±Ú©Øª: ${breakingVisual.randomMovement}, Ù…Ø§Ø¯Ù‡: ${breakingVisual.randomMaterial}, Ø´Ú©Ù„: ${breakingVisual.randomShape}`);

            // Step 4: MUSIC - Smart Music Selection
            setState((s) => ({ ...s, pipelineStep: "MUSIC" }));
            updateProductionStep('ğŸµ MUSIC', 'in_progress');
            const breakingMusicResult = await selectSmartMusic({
              musicTracks,
              queueIndex: state.currentQueueIdx,
              musicMood: contentPackage.theme.musicMood,
              topic: sourceSubject,
              fetchAudioBlob,
              onAddCloudTrack,
              setActiveTrackName,
              audioRef,
            });
            if (breakingMusicResult) {
              console.log(`ğŸµ [MUSIC] Selected: ${breakingMusicResult.title} from ${breakingMusicResult.source}`);
              const breakingMusicTitlePreview = breakingMusicResult.title.length > 40 ? breakingMusicResult.title.substring(0, 40) + '...' : breakingMusicResult.title;
              updateProductionStep('ğŸµ MUSIC', 'completed', `Ù…Ù†Ø¨Ø¹: ${breakingMusicResult.source}, Ù‚Ø·Ø¹Ù‡: ${breakingMusicTitlePreview}`);
            } else {
              updateProductionStep('ğŸµ MUSIC', 'completed', 'Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯ - Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÙˆÙ† Ù…ÙˆØ³ÛŒÙ‚ÛŒ');
            }

            // Step 5: GENERATE - Create Visual Content
            setState((s) => ({ ...s, pipelineStep: "SYNTH" }));
            updateProductionStep('ğŸ¨ GENERATE', 'in_progress');
            const art = await generateArtImage(breakingVisual.randomStyle, contentPackage.visualPrompt);
            console.log(`ğŸ¨ [GENERATE] Image: ${art.imageUrl?.substring(0, 50)}..., Story: ${contentPackage.storyArc.hook}`);
            const breakingHookPreview = contentPackage.storyArc.hook.length > 50 ? contentPackage.storyArc.hook.substring(0, 50) + '...' : contentPackage.storyArc.hook;
            updateProductionStep('ğŸ¨ GENERATE', 'completed', `ØªØµÙˆÛŒØ± ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯ - Ø®Ø¨Ø±: ${breakingHookPreview}`);

            setPreferences((p) => ({
              ...p,
              subject: sourceSubject,
              style: breakingVisual.randomStyle,
              movement: breakingVisual.randomMovement,
              material: breakingVisual.randomMaterial,
              shape: breakingVisual.randomShape,
              pieceCount: item.pieceCount,
              durationMinutes: item.duration,
              topicType: activeTopicType,
              topicCategory: categoryLabel,
              narrativeLens: contentPackage.theme.narrativeLens,
            }));

            setState((s) => ({
              ...s,
              imageUrl: art.imageUrl,
              storyArc: contentPackage.storyArc,
              docSnippets: [],
              isGenerating: false,
              pipelineStep: "METADATA",
            }));

            // Step 6: METADATA - Generate metadata
            updateProductionStep('ğŸ“‹ METADATA', 'in_progress');
            setIsMetadataLoading(true);
            setMetadata(contentPackage.metadata);
            setIsMetadataLoading(false);
            console.log(`ğŸ“‹ [METADATA] Title: ${contentPackage.metadata?.title}`);
            const metadataTitle = contentPackage.metadata?.title || 'Ù†Ø§Ù…Ø´Ø®Øµ';
            const titlePreview = metadataTitle.length > 50 ? metadataTitle.substring(0, 50) + '...' : metadataTitle;
            updateProductionStep('ğŸ“‹ METADATA', 'completed', `Ø¹Ù†ÙˆØ§Ù†: ${titlePreview}`);

            // Step 7: THUMBNAIL - Prepare thumbnail
            setState((s) => ({ ...s, pipelineStep: "THUMBNAIL" }));
            updateProductionStep('ğŸ–¼ï¸ THUMBNAIL', 'in_progress');
            console.log(`ğŸ–¼ï¸ [THUMBNAIL] Preparing thumbnail generation...`);
            updateProductionStep('ğŸ–¼ï¸ THUMBNAIL', 'completed', 'Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØªØ§Ù…Ø¨Ù†ÛŒÙ„');

            if (state.isAutoMode) {
              // Step 8: ANIMATE - Start animation
              updateProductionStep('ğŸ¬ ANIMATE', 'in_progress', 'Ø§Ù†ØªØ¸Ø§Ø± 10 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ú¯ÛŒ Ú©Ø§Ù…Ù„ Ù…Ø±ÙˆØ±Ú¯Ø±...');
              console.log(`â¸ï¸ [AutoPilot] Waiting 10 seconds for browser to prepare...`);
              setTimeout(
                () => {
                  setState((s) => ({ ...s, isSolving: true, isRecording: true, pipelineStep: "RECORDING" }));
                  updateProductionStep('ğŸ¬ ANIMATE', 'completed', 'Ø§Ù†ÛŒÙ…ÛŒØ´Ù† Ø¢ØºØ§Ø² Ø´Ø¯');
                  updateProductionStep('ğŸ¥ RECORD', 'in_progress', 'Ø¯Ø± Ø­Ø§Ù„ Ø¶Ø¨Ø· ÙˆÛŒØ¯Ø¦Ùˆ...');
                },
                10000
              );
            } else {
              setState((s) => ({ ...s, pipelineStep: "IDLE" }));
            }
          }
        } else {
          // MANUAL mode - use Coherent Content Package for consistency
          const randomNiche = VIRAL_CATEGORIES[Math.floor(Math.random() * VIRAL_CATEGORIES.length)];

          console.log(`ğŸ¯ MANUAL Mode: Generating coherent package for "${randomNiche.label}"`);
          const contentPackage = await generateCoherentContentPackage(sourceSubject, randomNiche.label);

          // Extract core subject for database save
          const coreSubject = await extractCoreSubject(
            contentPackage.visualPrompt,
            contentPackage.storyArc,
            randomNiche.label
          );

          // Store for later database save
          setCurrentCoreSubject(coreSubject);
          setCurrentVisualPrompt(contentPackage.visualPrompt);

          setState((s) => ({ ...s, pipelineStep: "MUSIC" }));
          // ğŸµ Smart Music Selection with Priority (Manual Mode doesn't use queue)
          await selectSmartMusic({
            musicTracks,
            queueIndex: 0, // Manual mode doesn't track queue index
            musicMood: contentPackage.theme.musicMood,
            topic: sourceSubject,
            fetchAudioBlob,
            onAddCloudTrack,
            setActiveTrackName,
            audioRef,
          });

          setState((s) => ({ ...s, pipelineStep: "SYNTH" }));
          const finalStyle = preferences.style;
          const art = await generateArtImage(finalStyle, contentPackage.visualPrompt);

          setPreferences((p) => ({
            ...p,
            subject: contentPackage.visualPrompt,
            narrativeLens: contentPackage.theme.narrativeLens,
          }));

          setState((s) => ({
            ...s,
            imageUrl: art.imageUrl,
            storyArc: contentPackage.storyArc,
            docSnippets: [],
            isGenerating: false,
            pipelineStep: "METADATA",
          }));

          setIsMetadataLoading(true);
          setMetadata(contentPackage.metadata);
          setIsMetadataLoading(false);

          setState((s) => ({ ...s, pipelineStep: "THUMBNAIL" }));
          setState((s) => ({ ...s, pipelineStep: "IDLE" }));
        }
      } catch (e) {
        console.error("Pipeline error:", e);
        setState((s) => ({
          ...s,
          isAutoMode: false,
          isGenerating: false,
          pipelineStep: "IDLE",
          error: "Neural Engine Sync Error",
        }));
      }
    },
    [preferences, state.isAutoMode, onAddCloudTrack, setActiveTrackName, setPreferences, fetchAudioBlob]
  );

  const toggleAutoMode = useCallback(() => {
    setState((s) => {
      const active = !s.isAutoMode;
      return {
        ...s,
        isAutoMode: active,
        isFullPackage: active,
        pipelineStep: active ? "IDLE" : s.pipelineStep,
        queue: active
          ? [
              // Queue mØ·Ø§Ø¨Ù‚ AUTO_PILOT_STRATEGY.md v6.0
              { duration: 0.5, source: "VIRAL", pieceCount: 100 },    // 30s - Hook & Fast Reveal
              { duration: 0.75, source: "VIRAL", pieceCount: 300 },   // 45s - Retention Test
              { duration: 1.0, source: "VIRAL", pieceCount: 500 },    // 60s - Full Engagement
              { duration: 1.5, source: "VIRAL", pieceCount: 2000 },   // 90s - Deep Dive
              { duration: 1.0, source: "BREAKING", pieceCount: 500 }, // 60s - Trending & Timely
              { duration: 1.0, source: "NARRATIVE", pieceCount: 900 },// 60s - High Detail Finale
            ]
          : s.queue,
        currentQueueIdx: active ? 0 : s.currentQueueIdx,
      };
    });
  }, []);

  useEffect(() => {
    if (state.isAutoMode && state.pipelineStep === "IDLE" && state.currentQueueIdx !== -1) {
      processPipelineItem(state.queue[state.currentQueueIdx], false);
    }
  }, [state.isAutoMode, state.pipelineStep, state.currentQueueIdx, processPipelineItem]);

  return {
    state,
    setState,
    metadata,
    isMetadataLoading,
    thumbnailDataUrl,
    setThumbnailDataUrl,
    setLastVideoBlob,
    processPipelineItem,
    toggleAutoMode,
  };
};
